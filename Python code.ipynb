{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тип text_train: <type 'list'>\n",
      "длина text_train: 25000\n",
      "text_train[1]:\n",
      "Words can't describe how bad this movie is. I can't explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clichés, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won't list them here, but just mention the coloring of the plane. They didn't even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you're choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "reviews_train = load_files(\"C:/Users/Asus/Downloads/aclImdb_v1.tar/aclImdb_v1/aclImdb/train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(\"тип text_train: {}\".format(type(text_train)))\n",
    "print(\"длина text_train: {}\".format(len(text_train)))\n",
    "print(\"text_train[1]:\\n{}\".format(text_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество примеров на класс (обучение): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество примеров на класс (обучение): {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество документов в текстовых данных: 25000\n",
      "Количество примеров на класс (тест): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "reviews_test = load_files(\"C:/Users/Asus/Downloads/aclImdb_v1.tar/aclImdb_v1/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"Количество документов в текстовых данных: {}\".format(len(text_test)))\n",
    "print(\"Количество примеров на класс (тест): {}\".format(np.bincount(y_test)))\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise\", \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 13\n",
      "Содержимое словаря:\n",
      " {u'fool': 3, u'be': 0, u'he': 4, u'himself': 5, u'wise': 12, u'knows': 7, u'is': 6, u'but': 1, u'to': 11, u'the': 9, u'doth': 2, u'think': 10, u'man': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер словаря: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"Содержимое словаря:\\n {}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words: <2x13 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print(\"bag_of_words: {}\".format(repr(bag_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Плотное представление bag_of_words:\n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Плотное представление bag_of_words:\\n{}\".format(bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x74849 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков: 74849\n",
      "Первые 20 признаков:\n",
      "[u'00', u'000', u'0000000000001', u'00001', u'00015', u'000s', u'001', u'003830', u'006', u'007', u'0079', u'0080', u'0083', u'0093638', u'00am', u'00pm', u'00s', u'01', u'01pm', u'02']\n",
      "Признаки с 20010 по 20030:\n",
      "[u'dratted', u'draub', u'draught', u'draughts', u'draughtswoman', u'draw', u'drawback', u'drawbacks', u'drawer', u'drawers', u'drawing', u'drawings', u'drawl', u'drawled', u'drawling', u'drawn', u'draws', u'draza', u'dre', u'drea']\n",
      "Каждый 2000-й признак:\n",
      "[u'00', u'aesir', u'aquarian', u'barking', u'blustering', u'b\\xeate', u'chicanery', u'condensing', u'cunning', u'detox', u'draper', u'enshrined', u'favorit', u'freezer', u'goldman', u'hasan', u'huitieme', u'intelligible', u'kantrowitz', u'lawful', u'maars', u'megalunged', u'mostey', u'norrland', u'padilla', u'pincher', u'promisingly', u'receptionist', u'rivals', u'schnaas', u'shunning', u'sparse', u'subset', u'temptations', u'treatises', u'unproven', u'walkman', u'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Количество признаков: {}\".format(len(feature_names)))\n",
    "print(\"Первые 20 признаков:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Признаки с 20010 по 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Каждый 2000-й признак:\\n{}\".format(format(feature_names[::2000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя правильность перекр проверки: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Средняя правильность перекр проверки: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее занчение перекрёстной проеврки: 0.89\n",
      "('\\xd0\\x9d\\xd0\\xb0\\xd0\\xb8\\xd0\\xbb\\xd1\\x83\\xd1\\x87\\xd1\\x88\\xd0\\xb8\\xd0\\xb5 \\xd0\\xbf\\xd0\\xb0\\xd1\\x80\\xd0\\xb0\\xd0\\xbc\\xd0\\xb5\\xd1\\x82\\xd1\\x80\\xd1\\x8b: ', {'C': 0.1})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Наилучшее занчение перекрёстной проеврки: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Наилучшие параметры: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на тестовом наборе: 0.88\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Правильность на тестовом наборе: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train с min df: <25000x27271 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 3354014 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train с min df: {}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 50 признаков:\n",
      "[u'00', u'000', u'007', u'00s', u'01', u'02', u'03', u'04', u'05', u'06', u'07', u'08', u'09', u'10', u'100', u'1000', u'100th', u'101', u'102', u'103', u'104', u'105', u'107', u'108', u'10s', u'10th', u'11', u'110', u'112', u'116', u'117', u'11th', u'12', u'120', u'12th', u'13', u'135', u'13th', u'14', u'140', u'14th', u'15', u'150', u'15th', u'16', u'160', u'1600', u'16mm', u'16s', u'16th']\n",
      "Признаки с 20010 по 20030:\n",
      "[u'repentance', u'repercussions', u'repertoire', u'repetition', u'repetitions', u'repetitious', u'repetitive', u'rephrase', u'replace', u'replaced', u'replacement', u'replaces', u'replacing', u'replay', u'replayable', u'replayed', u'replaying', u'replays', u'replete', u'replica']\n",
      "Каждый 700-й признак:\n",
      "[u'00', u'affections', u'appropriately', u'barbra', u'blurbs', u'butchered', u'cheese', u'commitment', u'courts', u'deconstructed', u'disgraceful', u'dvds', u'eschews', u'fell', u'freezer', u'goriest', u'hauser', u'hungary', u'insinuate', u'juggle', u'leering', u'maelstrom', u'messiah', u'music', u'occasional', u'parking', u'pleasantville', u'pronunciation', u'recipient', u'reviews', u'sas', u'shea', u'sneers', u'steiger', u'swastika', u'thrusting', u'tvs', u'vampyre', u'westerns']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Первые 50 признаков:\\n{}\".format(feature_names[:50]))\n",
    "print(\"Признаки с 20010 по 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Каждый 700-й признак:\\n{}\".format(feature_names[::700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение перекр проверки: 0.89\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Наилучшее значение перекр проверки: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество стоп-слов: 318\n",
      "Каждое 10-е стоп-слово:\n",
      "['all', 'not', 'one', 'should', 'latterly', 'cannot', 'name', 'each', 'ten', 'beyond', 'mine', 'between', 'full', 'found', 'anything', 'became', 'formerly', 'everyone', 'three', 'anyone', 'was', 'becoming', 'he', 'besides', 'and', 'an', 'fill', 'when', 'becomes', 'hereupon', 'whereby', 'rather']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"Количество стоп-слов: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "print(\"Каждое 10-е стоп-слово:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train с использованием стоп-слов:\n",
      "<25000x26966 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 2149958 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# настройка stop_words=\"english\" задаёт встроенный списон стоп-слов.\n",
    "# в него можно передать свой список.\n",
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train с использованием стоп-слов:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение перекр проверки: 0.88\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Наилучшее значение перекр проверки: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
